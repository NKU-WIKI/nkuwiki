#!/usr/bin/env python3
"""
é«˜çº§RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç®¡é“

æœ¬æ¨¡å—æä¾›äº†ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„RAGç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥å’Œé‡æ’åºæ–¹æ¡ˆçš„çµæ´»ç»„åˆã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸ” å¤šæ£€ç´¢å™¨æ”¯æŒ
- **å‘é‡æ£€ç´¢ (Vector)**: åŸºäºBGEè¯­ä¹‰åµŒå…¥çš„ç›¸ä¼¼åº¦æœç´¢
- **BM25æ£€ç´¢ (BM25)**: åŸºäºTF-IDFçš„å…³é”®è¯åŒ¹é…
- **æ··åˆæ£€ç´¢ (Hybrid)**: èåˆå‘é‡å’ŒBM25çš„RRFç®—æ³•
- **Elasticsearch**: æ”¯æŒé€šé…ç¬¦å’Œå¤æ‚æŸ¥è¯¢çš„å…¨æ–‡æ£€ç´¢

### ğŸ¯ æ™ºèƒ½æ£€ç´¢ç­–ç•¥
- **AUTO**: æ ¹æ®æŸ¥è¯¢ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥
- **VECTOR_ONLY**: çº¯è¯­ä¹‰æ£€ç´¢ï¼Œé€‚åˆæ¦‚å¿µæ€§æŸ¥è¯¢
- **BM25_ONLY**: çº¯å…³é”®è¯æ£€ç´¢ï¼Œé€‚åˆç²¾ç¡®åŒ¹é…
- **HYBRID**: æ··åˆæ£€ç´¢ï¼Œå¹³è¡¡è¯­ä¹‰å’Œå…³é”®è¯
- **ELASTICSEARCH_ONLY**: å…¨æ–‡æ£€ç´¢ï¼Œæ”¯æŒé€šé…ç¬¦

### âš¡ å¤šé‡æ’åºç­–ç•¥
- **BGE_RERANKER**: ä½¿ç”¨BGEé‡æ’åºæ¨¡å‹çš„æ·±åº¦è¯­ä¹‰é‡æ’
- **SENTENCE_TRANSFORMER**: åŸºäºäº¤å‰ç¼–ç å™¨çš„é‡æ’åº
- **PAGERANK_ONLY**: åŸºäºé¡µé¢æƒå¨æ€§çš„æ’åº
- **PERSONALIZED**: ç»“åˆç”¨æˆ·å†å²çš„ä¸ªæ€§åŒ–æ’åº
- **NO_RERANK**: ä½¿ç”¨åŸå§‹æ£€ç´¢åˆ†æ•°

### ğŸ§  æ™ºèƒ½è·¯ç”±æœºåˆ¶
ç³»ç»Ÿä¼šæ ¹æ®æŸ¥è¯¢ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥ï¼š
- é€šé…ç¬¦æŸ¥è¯¢ (`*`, `?`) â†’ Elasticsearch
- é•¿æŸ¥è¯¢æˆ–é—®å¥ â†’ æ··åˆæ£€ç´¢
- çŸ­æŸ¥è¯¢æˆ–ä¸“æœ‰åè¯ â†’ BM25æ£€ç´¢
- æ¦‚å¿µæ€§æŸ¥è¯¢ â†’ å‘é‡æ£€ç´¢

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ç”¨æ³•
```python
from etl.rag_pipeline import RagPipeline, RetrievalStrategy, RerankStrategy

# åˆå§‹åŒ–ç®¡é“
rag = RagPipeline()

# è‡ªåŠ¨ç­–ç•¥ï¼ˆæ¨èï¼‰
result = rag.run("å—å¼€å¤§å­¦çš„æ ¡è®­æ˜¯ä»€ä¹ˆï¼Ÿ")

# æŒ‡å®šç­–ç•¥ç»„åˆ
result = rag.run(
    "äººå·¥æ™ºèƒ½*ç®—æ³•",
    retrieval_strategy=RetrievalStrategy.ELASTICSEARCH_ONLY,
    rerank_strategy=RerankStrategy.BGE_RERANKER
)
```

### é«˜çº§ç”¨æ³•
```python
# ä¸ªæ€§åŒ–æ£€ç´¢
result = rag.run(
    "è®¡ç®—æœºä¸“ä¸šè¯¾ç¨‹",
    user_id="user123",
    retrieval_strategy=RetrievalStrategy.HYBRID,
    rerank_strategy=RerankStrategy.PERSONALIZED
)

# ä»…æ£€ç´¢æ¨¡å¼ï¼ˆè·³è¿‡LLMç”Ÿæˆï¼‰
result = rag.retrieve_only(
    "æœºå™¨å­¦ä¹ ",
    retrieval_strategy=RetrievalStrategy.VECTOR_ONLY,
    rerank_strategy=RerankStrategy.PAGERANK_ONLY
)

# å¸¦è¿‡æ»¤å™¨çš„æ£€ç´¢
from qdrant_client import models
filters = models.Filter(
    must=[models.FieldCondition(
        key="metadata.source", 
        match=models.MatchValue(value="academic")
    )]
)
result = rag.run("æ·±åº¦å­¦ä¹ ", filters=filters)
```

### ç­–ç•¥æ€§èƒ½å¯¹æ¯”
| æ£€ç´¢ç­–ç•¥ | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|---------|---------|------|------|
| AUTO | é€šç”¨åœºæ™¯ | æ™ºèƒ½é€‰æ‹© | å¯èƒ½ä¸æ˜¯æœ€ä¼˜ |
| VECTOR_ONLY | æ¦‚å¿µæŸ¥è¯¢ | è¯­ä¹‰ç†è§£å¼º | å…³é”®è¯åŒ¹é…å¼± |
| BM25_ONLY | ç²¾ç¡®åŒ¹é… | å…³é”®è¯åŒ¹é…å¼º | è¯­ä¹‰ç†è§£å¼± |
| HYBRID | å¹³è¡¡éœ€æ±‚ | ç»¼åˆæ•ˆæœå¥½ | è®¡ç®—å¼€é”€å¤§ |
| ELASTICSEARCH_ONLY | å¤æ‚æŸ¥è¯¢ | åŠŸèƒ½å¼ºå¤§ | éœ€è¦ESæœåŠ¡ |

| é‡æ’åºç­–ç•¥ | é€‚ç”¨åœºæ™¯ | ç‰¹ç‚¹ |
|-----------|---------|------|
| BGE_RERANKER | è´¨é‡ä¼˜å…ˆ | æ•ˆæœæœ€ä½³ï¼Œé€Ÿåº¦è¾ƒæ…¢ |
| SENTENCE_TRANSFORMER | å¹³è¡¡é€‰æ‹© | æ•ˆæœè‰¯å¥½ï¼Œé€Ÿåº¦é€‚ä¸­ |
| PAGERANK_ONLY | æƒå¨æ€§ä¼˜å…ˆ | åŸºäºé¡µé¢æƒå¨æ€§ |
| PERSONALIZED | ä¸ªæ€§åŒ–éœ€æ±‚ | ç»“åˆç”¨æˆ·å†å² |
| NO_RERANK | é€Ÿåº¦ä¼˜å…ˆ | æœ€å¿«ï¼Œæ— é‡æ’å¼€é”€ |

## é…ç½®å‚æ•°

åœ¨ `config.json` ä¸­å¯é…ç½®ä»¥ä¸‹å‚æ•°ï¼š

```json
{
  "etl": {
    "retrieval": {
      "pagerank_weight": 0.1,
      "enable_es_rerank": true,
      "bm25": {
        "nodes_path": "/data/index/bm25_nodes.pkl",
        "stopwords_path": "/data/nltk/hit_stopwords.txt"
      }
    },
    "data": {
      "qdrant": {
        "url": "http://localhost:6333",
        "collection": "main_index"
      },
      "elasticsearch": {
        "host": "localhost", 
        "port": 9200,
        "index": "nkuwiki"
      }
    }
  }
}
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ç¼“å­˜ç­–ç•¥**: å¯ç”¨åµŒå…¥æ¨¡å‹ç¼“å­˜
2. **æ‰¹å¤„ç†**: å¯¹å¤§é‡æŸ¥è¯¢ä½¿ç”¨æ‰¹å¤„ç†
3. **æœåŠ¡é¢„çƒ­**: æå‰åŠ è½½æ¨¡å‹å’Œç´¢å¼•
4. **èµ„æºç›‘æ§**: ç›‘æ§å†…å­˜å’Œè®¡ç®—èµ„æºä½¿ç”¨
5. **ç­–ç•¥é€‰æ‹©**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„ç­–ç•¥ç»„åˆ

## æ³¨æ„äº‹é¡¹

- ç¡®ä¿æ‰€æœ‰ä¾èµ–æœåŠ¡ï¼ˆQdrant, Elasticsearch, MySQLï¼‰æ­£å¸¸è¿è¡Œ
- æ¨¡å‹æ–‡ä»¶éœ€è¦é¢„å…ˆä¸‹è½½åˆ°æŒ‡å®šç›®å½•
- é‡æ’åºä¼šå¢åŠ å“åº”æ—¶é—´ä½†æå‡ç»“æœè´¨é‡
- ä¸ªæ€§åŒ–åŠŸèƒ½éœ€è¦ç”¨æˆ·æœç´¢å†å²æ•°æ®

ä½œè€…: nkuwiki-IR-lab
ç‰ˆæœ¬: 2.0.0
"""

import os
import sys
import asyncio
import time
from pathlib import Path
import logging
from typing import List, Optional, Dict, Any
import jieba
from enum import Enum
import nest_asyncio

# LlamaIndexæ ¸å¿ƒç»„ä»¶
from llama_index.core import Settings, QueryBundle
from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler, TokenCountingHandler
from llama_index.core.schema import NodeWithScore
from llama_index.vector_stores.qdrant import QdrantVectorStore
from qdrant_client import QdrantClient, models

# é¡¹ç›®ä¾èµ–
sys.path.append(str(Path(__file__).resolve().parent.parent))
from etl.embedding.hf_embeddings import HuggingFaceEmbedding
from etl.retrieval.rerankers import SentenceTransformerRerank, LLMRerank
from etl.retrieval.retrievers import QdrantRetriever, BM25Retriever, HybridRetriever, ElasticsearchRetriever
from config import Config
from core.utils import register_logger
from core.agent.agent_factory import get_agent

# é…ç½®æ—¥å¿—å’Œå…¨å±€è®¾ç½®
logger = register_logger(__name__)
config = Config()

# åˆå§‹åŒ–LlamaIndexå…¨å±€è®¾ç½®
Settings.callback_manager = CallbackManager([
    LlamaDebugHandler(),
    TokenCountingHandler()
])
Settings.num_output = 512
Settings.chunk_size = config.get("etl.embedding.chunking.chunk_size", 512)
Settings.chunk_overlap = config.get("etl.embedding.chunking.chunk_overlap", 200)


class RetrievalStrategy(Enum):
    """æ£€ç´¢ç­–ç•¥æšä¸¾"""
    VECTOR_ONLY = "vector_only"           # ä»…å‘é‡æ£€ç´¢
    BM25_ONLY = "bm25_only"              # ä»…BM25æ£€ç´¢
    HYBRID = "hybrid"                     # æ··åˆæ£€ç´¢ï¼ˆå‘é‡+BM25ï¼‰
    ELASTICSEARCH_ONLY = "es_only"        # ä»…Elasticsearchæ£€ç´¢
    AUTO = "auto"                         # è‡ªåŠ¨é€‰æ‹©ï¼ˆåŸºäºæŸ¥è¯¢ç‰¹å¾ï¼‰


class RerankStrategy(Enum):
    """é‡æ’åºç­–ç•¥æšä¸¾"""
    NO_RERANK = "no_rerank"              # ä¸é‡æ’åº
    BGE_RERANKER = "bge_reranker"        # BGEé‡æ’åºå™¨
    SENTENCE_TRANSFORMER = "st_reranker" # SentenceTransformeré‡æ’åºå™¨
    PAGERANK_ONLY = "pagerank_only"      # ä»…PageRankæ’åº
    PERSONALIZED = "personalized"        # ä¸ªæ€§åŒ–æ’åº


# ç§»é™¤æœªä½¿ç”¨çš„å·¥å…·å‡½æ•°ï¼Œè¿™äº›åŠŸèƒ½å·²é›†æˆåˆ°ç›¸åº”çš„ç±»æ–¹æ³•ä¸­


nest_asyncio.apply()

class RagPipeline:
    """
    é«˜çº§RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç®¡é“ï¼Œæ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥ç»„åˆã€‚
    
    æ£€ç´¢ç­–ç•¥ï¼š
    - VECTOR_ONLY: çº¯è¯­ä¹‰å‘é‡æ£€ç´¢ï¼Œé€‚åˆæ¦‚å¿µæ€§æŸ¥è¯¢
    - BM25_ONLY: çº¯å…³é”®è¯æ£€ç´¢ï¼Œé€‚åˆç²¾ç¡®åŒ¹é…
    - HYBRID: æ··åˆæ£€ç´¢ï¼Œèåˆè¯­ä¹‰å’Œå…³é”®è¯ï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
    - ELASTICSEARCH_ONLY: å…¨æ–‡æ£€ç´¢ï¼Œé€‚åˆå¤æ‚æŸ¥è¯¢å’Œé€šé…ç¬¦
    - AUTO: è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥
    
    é‡æ’åºç­–ç•¥ï¼š
    - NO_RERANK: ä½¿ç”¨åŸå§‹æ£€ç´¢åˆ†æ•°
    - BGE_RERANKER: ä½¿ç”¨BGEé‡æ’åºæ¨¡å‹
    - SENTENCE_TRANSFORMER: ä½¿ç”¨SentenceTransformeré‡æ’åº
    - PAGERANK_ONLY: ä»…åŸºäºé¡µé¢æƒå¨æ€§æ’åº
    - PERSONALIZED: ç»“åˆç”¨æˆ·å†å²çš„ä¸ªæ€§åŒ–æ’åº
    """
    
    def __init__(self,
                 llm_model_name: str = "deepseek-chat",
                 embedding_model_name: str = "BAAI/bge-large-zh-v1.5",
                 rerank_model_name: str = "BAAI/bge-reranker-base",
                 collection_name: str = None,
                 es_index_name: str = None,
                 pagerank_weight: float = None,
                 enable_es_rerank: bool = None,
                 default_retrieval_strategy: RetrievalStrategy = RetrievalStrategy.AUTO,
                 default_rerank_strategy: RerankStrategy = RerankStrategy.BGE_RERANKER
                 ):
        """
        åˆå§‹åŒ–RAGç®¡é“ã€‚
        
        Args:
            llm_model_name: è¯­è¨€æ¨¡å‹åç§°
            embedding_model_name: åµŒå…¥æ¨¡å‹åç§°
            rerank_model_name: é‡æ’åºæ¨¡å‹åç§°
            collection_name: Qdranté›†åˆåç§°
            es_index_name: Elasticsearchç´¢å¼•åç§°
            pagerank_weight: PageRankæƒé‡
            enable_es_rerank: æ˜¯å¦å¯¹ESç»“æœé‡æ’åº
            default_retrieval_strategy: é»˜è®¤æ£€ç´¢ç­–ç•¥
            default_rerank_strategy: é»˜è®¤é‡æ’åºç­–ç•¥
        """
        logger.info("Initializing RAG pipeline...")
        self.collection_name = collection_name or config.get('etl.data.qdrant.collection', 'website_nku')
        self.es_index_name = es_index_name or config.get('etl.data.elasticsearch.index', 'nkuwiki')
        
        # ç­–ç•¥é…ç½®
        self.default_retrieval_strategy = default_retrieval_strategy
        self.default_rerank_strategy = default_rerank_strategy
        
        # PageRankå’Œé‡æ’åºé…ç½®
        self.pagerank_weight = pagerank_weight if pagerank_weight is not None else config.get('etl.retrieval.pagerank_weight', 0.1)
        self.enable_es_rerank = enable_es_rerank if enable_es_rerank is not None else config.get('etl.retrieval.enable_es_rerank', True)
        
        logger.info(f"Default retrieval strategy: {self.default_retrieval_strategy.value}")
        logger.info(f"Default rerank strategy: {self.default_rerank_strategy.value}")
        logger.info(f"PageRank weight: {self.pagerank_weight}, ES rerank enabled: {self.enable_es_rerank}")

        # 1. åˆå§‹åŒ–è¯­è¨€æ¨¡å‹ (LLM)
        self.llm = self._init_llm(llm_model_name)
        
        # 2. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ (Embedding)
        self.embed_model = self._init_embedding_model(embedding_model_name)
        Settings.embed_model = self.embed_model

        # 3. åˆå§‹åŒ–é‡æ’æ¨¡å‹ (Reranker)
        self.reranker = self._init_reranker(rerank_model_name)

        # 4. åˆå§‹åŒ–æ£€ç´¢å™¨ (Retrievers)
        self.vector_retriever = self._init_vector_retriever()
        self.bm25_retriever = self._init_bm25_retriever()
        self.hybrid_retriever = self._init_hybrid_retriever()
        self.es_retriever = self._init_es_retriever()
        
        # 5. è®°å½•å¯ç”¨çš„æ£€ç´¢å™¨
        self.available_retrievers = self._check_available_retrievers()
        logger.info(f"Available retrievers: {list(self.available_retrievers.keys())}")
        
        logger.info("RAG pipeline initialized successfully.")

    def _init_llm(self, model_name: str):
        logger.info(f"Initializing LLM: {model_name}")
        # ä½¿ç”¨coze agentæ›¿ä»£llama-indexçš„OpenAI LLMï¼ŒæŒ‡å®šä½¿ç”¨answerGenerate_bot_id
        return get_agent("coze", tag="answerGenerate")

    def _init_embedding_model(self, model_name: str):
        logger.info(f"Initializing embedding model: {model_name}")
        # æ ¹æ®é…ç½®æ–‡ä»¶é€»è¾‘ï¼šbase_path + models.path
        import os
        base_path = config.get('etl.data.base_path', '/data')
        models_subpath = config.get('etl.data.models.path', '/models')
        models_path = base_path + models_subpath
        
        # å…¨å±€è®¾ç½®HuggingFaceç¼“å­˜ç›®å½•
        os.environ['HF_HOME'] = models_path
        os.environ['TRANSFORMERS_CACHE'] = models_path
        os.environ['HF_HUB_CACHE'] = models_path
        os.environ['SENTENCE_TRANSFORMERS_HOME'] = models_path
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(models_path, exist_ok=True)
        logger.info(f"Models cache directory set to: {models_path}")
        
        # ä½¿ç”¨é¡¹ç›®çš„ HuggingFaceEmbedding ç±»ï¼Œå®ƒå·²ç»ç»§æ‰¿è‡ª BaseEmbedding
        from etl.embedding.hf_embeddings import HuggingFaceEmbedding
        import torch
        
        # å¼ºåˆ¶ä½¿ç”¨CPUä»¥é¿å…å†…å­˜ä¸è¶³é—®é¢˜
        device = 'cpu'
        logger.info("å¼ºåˆ¶ä½¿ç”¨CPUè®¾å¤‡")
        
        logger.info(f"Loading model {model_name} from {models_path} on {device}")
        try:
            return HuggingFaceEmbedding(
                model_name=model_name,
                device=device
            )
        except Exception as e:
            logger.error(f"Failed to initialize embedding model: {e}")
            raise

    def _init_reranker(self, model_name: str):
        logger.info(f"Initializing reranker: {model_name}")
        # æ ¹æ®æ¨¡å‹åç§°é€‰æ‹©åˆé€‚çš„é‡æ’åºå™¨
        if "bge-reranker" in model_name.lower():
            return LLMRerank(model=model_name, top_n=10, pagerank_weight=self.pagerank_weight)
        else:
            return SentenceTransformerRerank(model=model_name, top_n=10, pagerank_weight=self.pagerank_weight)

    def _load_stopwords(self):
        """åŠ è½½åœç”¨è¯æ–‡ä»¶"""
        stopwords_path = config.get('etl.retrieval.bm25.stopwords_path')
        try:
            with open(stopwords_path, 'r', encoding='utf-8') as f:
                return [line.strip() for line in f.readlines()]
        except FileNotFoundError:
            logger.warning(f"Stopwords file not found at {stopwords_path}. Returning empty list.")
            return []

    def _init_vector_retriever(self):
        logger.info("Initializing QdrantRetriever.")
        qdrant_url = config.get('etl.data.qdrant.url', 'http://localhost:6333')
        qdrant_client = QdrantClient(url=qdrant_url)
        vector_store = QdrantVectorStore(client=qdrant_client, collection_name=self.collection_name)
        return QdrantRetriever(vector_store=vector_store, embed_model=self.embed_model, similarity_top_k=10)

    def _init_bm25_retriever(self):
        logger.info("Initializing BM25Retriever using fast mode.")
        nodes_path = config.get('etl.retrieval.bm25.nodes_path')
        
        # æ£€æŸ¥é¢„æ„å»ºçš„èŠ‚ç‚¹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not nodes_path or not os.path.exists(nodes_path):
            logger.warning(f"BM25èŠ‚ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {nodes_path}. BM25æ£€ç´¢å™¨å°†è¢«ç¦ç”¨.")
            return None
        
        try:
            # ä½¿ç”¨å¿«é€ŸåŠ è½½æ–¹æ³•
            stopwords = self._load_stopwords()
            return BM25Retriever.from_pickle_fast(
                nodes_path=nodes_path,
                tokenizer=jieba,
                stopwords=stopwords,
                similarity_top_k=10
            )
        except Exception as e:
            logger.error(f"BM25æ£€ç´¢å™¨å¿«é€ŸåŠ è½½å¤±è´¥: {e}")
            return None

    def _init_hybrid_retriever(self):
        """åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨"""
        if self.vector_retriever and self.bm25_retriever:
            logger.info("Initializing HybridRetriever with vector and BM25 retrievers.")
            return HybridRetriever(
                dense_retriever=self.vector_retriever,
                sparse_retriever=self.bm25_retriever,
                pagerank_weight=self.pagerank_weight
            )
        logger.warning("Cannot initialize HybridRetriever: missing vector or BM25 retriever.")
        return None

    def _init_es_retriever(self):
        """åˆå§‹åŒ–Elasticsearchæ£€ç´¢å™¨"""
        logger.info("Initializing ElasticsearchRetriever.")
        es_host = config.get('etl.data.elasticsearch.host', 'localhost')
        es_port = config.get('etl.data.elasticsearch.port', 9200)
        try:
            return ElasticsearchRetriever(
                index_name=self.es_index_name, 
                es_host=es_host, 
                es_port=es_port, 
                similarity_top_k=10
            )
        except Exception as e:
            logger.warning(f"Failed to initialize ElasticsearchRetriever: {e}. Wildcard search will be disabled.")
            return None

    def _check_available_retrievers(self) -> Dict[str, bool]:
        """æ£€æŸ¥å¯ç”¨çš„æ£€ç´¢å™¨"""
        return {
            "vector": self.vector_retriever is not None,
            "bm25": self.bm25_retriever is not None,
            "hybrid": self.hybrid_retriever is not None,
            "elasticsearch": self.es_retriever is not None
        }

    def _determine_retrieval_strategy(self, query: str) -> RetrievalStrategy:
        """æ ¹æ®æŸ¥è¯¢å†…å®¹è‡ªåŠ¨ç¡®å®šæœ€ä¼˜æ£€ç´¢ç­–ç•¥"""
        # é€šé…ç¬¦æŸ¥è¯¢ -> Elasticsearch
        if '*' in query or '?' in query:
            if self.available_retrievers.get("elasticsearch"):
                return RetrievalStrategy.ELASTICSEARCH_ONLY
        
        # é•¿æŸ¥è¯¢ï¼ˆ>20å­—ç¬¦ï¼‰æˆ–åŒ…å«é—®å¥ -> æ··åˆæ£€ç´¢
        if len(query) > 20 or any(char in query for char in ['ï¼Ÿ', '?', 'å¦‚ä½•', 'ä»€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'æ€ä¹ˆ']):
            if self.available_retrievers.get("hybrid"):
                return RetrievalStrategy.HYBRID
            elif self.available_retrievers.get("vector"):
                return RetrievalStrategy.VECTOR_ONLY
        
        # çŸ­æŸ¥è¯¢æˆ–ä¸“æœ‰åè¯ -> BM25
        if len(query) <= 10:
            if self.available_retrievers.get("bm25"):
                return RetrievalStrategy.BM25_ONLY
        
        # é»˜è®¤ä½¿ç”¨æ··åˆæ£€ç´¢
        if self.available_retrievers.get("hybrid"):
            return RetrievalStrategy.HYBRID
        elif self.available_retrievers.get("vector"):
            return RetrievalStrategy.VECTOR_ONLY
        elif self.available_retrievers.get("bm25"):
            return RetrievalStrategy.BM25_ONLY
        else:
            return RetrievalStrategy.ELASTICSEARCH_ONLY

    def retrieve(self, 
                query: str, 
                top_k: int = 10, 
                filters=None,
                strategy: Optional[RetrievalStrategy] = None) -> List[NodeWithScore]:
        """
        æ ¹æ®æŒ‡å®šç­–ç•¥æˆ–è‡ªåŠ¨é€‰æ‹©æ£€ç´¢å™¨è¿›è¡Œæ£€ç´¢ã€‚
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            top_k: è¿”å›ç»“æœæ•°é‡
            filters: Qdrantè¿‡æ»¤å™¨
            strategy: æ£€ç´¢ç­–ç•¥ï¼ŒNoneæ—¶ä½¿ç”¨é»˜è®¤ç­–ç•¥æˆ–è‡ªåŠ¨é€‰æ‹©
        """
        # ç¡®å®šæ£€ç´¢ç­–ç•¥
        if strategy is None:
            strategy = self.default_retrieval_strategy
        
        if strategy == RetrievalStrategy.AUTO:
            strategy = self._determine_retrieval_strategy(query)
        
        logger.info(f"Using retrieval strategy: {strategy.value} for query: '{query}'")
        
        query_bundle = QueryBundle(query_str=query)
        
        # æ‰§è¡Œæ£€ç´¢
        if strategy == RetrievalStrategy.VECTOR_ONLY:
            if not self.vector_retriever:
                logger.error("Vector retriever not available")
                return []
            if filters and hasattr(self.vector_retriever, 'filters'):
                self.vector_retriever.filters = filters
            retrieved_nodes = self.vector_retriever._retrieve(query_bundle)
            
        elif strategy == RetrievalStrategy.BM25_ONLY:
            if not self.bm25_retriever:
                logger.error("BM25 retriever not available")
                return []
            retrieved_nodes = self.bm25_retriever._retrieve(query_bundle)
            
        elif strategy == RetrievalStrategy.HYBRID:
            if not self.hybrid_retriever:
                logger.error("Hybrid retriever not available")
                return []
            if filters and self.vector_retriever and hasattr(self.vector_retriever, 'filters'):
                self.vector_retriever.filters = filters
            retrieved_nodes = self.hybrid_retriever._retrieve(query_bundle)
            
        elif strategy == RetrievalStrategy.ELASTICSEARCH_ONLY:
            if not self.es_retriever:
                logger.error("Elasticsearch retriever not available")
                return []
            retrieved_nodes = self.es_retriever._retrieve(query_bundle)
            
        else:
            logger.error(f"Unknown retrieval strategy: {strategy}")
            return []
        
        logger.info(f"Retrieved {len(retrieved_nodes)} documents using {strategy.value}")
        return retrieved_nodes[:top_k]

    def rerank(self, 
              query: str, 
              retrieved_nodes: List[NodeWithScore], 
              top_n: int = 5,
              search_history: List[str] = None,
              strategy: Optional[RerankStrategy] = None,
              is_elasticsearch: bool = False) -> List[NodeWithScore]:
        """
        æ ¹æ®æŒ‡å®šç­–ç•¥å¯¹æ£€ç´¢ç»“æœè¿›è¡Œé‡æ’åºã€‚
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            retrieved_nodes: æ£€ç´¢åˆ°çš„èŠ‚ç‚¹
            top_n: è¿”å›çš„èŠ‚ç‚¹æ•°é‡
            search_history: ç”¨æˆ·æœç´¢å†å²
            strategy: é‡æ’åºç­–ç•¥
            is_elasticsearch: æ˜¯å¦ä¸ºElasticsearchç»“æœ
        """
        if strategy is None:
            strategy = self.default_rerank_strategy
        
        logger.info(f"Using rerank strategy: {strategy.value}")
        
        # ç‰¹æ®Šå¤„ç†ï¼šElasticsearchç»“æœä¸”é…ç½®ä¸ºä¸é‡æ’åº
        if is_elasticsearch and not self.enable_es_rerank and strategy != RerankStrategy.NO_RERANK:
            logger.info("Elasticsearchç»“æœè·³è¿‡é‡æ’åºï¼Œä»…åº”ç”¨ä¸ªæ€§åŒ–ææƒ")
            strategy = RerankStrategy.PERSONALIZED
        
        # æ‰§è¡Œé‡æ’åº
        if strategy == RerankStrategy.NO_RERANK:
            # ä»…æŒ‰åŸå§‹åˆ†æ•°æ’åº
            sorted_nodes = sorted(retrieved_nodes, key=lambda x: float(x.score or 0), reverse=True)
            return sorted_nodes[:top_n]
            
        elif strategy == RerankStrategy.PAGERANK_ONLY:
            # ä»…æŒ‰PageRankåˆ†æ•°æ’åº
            for node_with_score in retrieved_nodes:
                metadata = node_with_score.node.metadata if hasattr(node_with_score.node, 'metadata') else {}
                pagerank_score = metadata.get('pagerank_score', 0.0)
                node_with_score.score = float(pagerank_score)
            sorted_nodes = sorted(retrieved_nodes, key=lambda x: float(x.score or 0), reverse=True)
            return sorted_nodes[:top_n]
            
        elif strategy == RerankStrategy.PERSONALIZED:
            # ä»…åº”ç”¨ä¸ªæ€§åŒ–ææƒ
            if search_history:
                logger.info("åº”ç”¨ä¸ªæ€§åŒ–ææƒ...")
                history_keywords = set(search_history)
                for node_with_score in retrieved_nodes:
                    content = node_with_score.get_content().lower()
                    if any(keyword.lower() in content for keyword in history_keywords):
                        boost = 0.1
                        node_with_score.score += boost
                        logger.debug(f"èŠ‚ç‚¹ {node_with_score.node.node_id} å› åŒ¹é…å†å²è®°å½•è€Œè¢«ææƒ {boost}")
            sorted_nodes = sorted(retrieved_nodes, key=lambda x: float(x.score or 0), reverse=True)
            return sorted_nodes[:top_n]
            
        elif strategy in [RerankStrategy.BGE_RERANKER, RerankStrategy.SENTENCE_TRANSFORMER]:
            # ä½¿ç”¨é‡æ’åºæ¨¡å‹
            if not self.reranker:
                logger.warning("Reranker not initialized, falling back to no rerank")
                return self.rerank(query, retrieved_nodes, top_n, search_history, RerankStrategy.NO_RERANK, is_elasticsearch)
            
            # å…ˆåº”ç”¨ä¸ªæ€§åŒ–ææƒ
            if search_history:
                logger.info("åº”ç”¨ä¸ªæ€§åŒ–ææƒ...")
                history_keywords = set(search_history)
                for node_with_score in retrieved_nodes:
                    content = node_with_score.get_content().lower()
                    if any(keyword.lower() in content for keyword in history_keywords):
                        boost = 0.1
                        node_with_score.score += boost
                        logger.debug(f"èŠ‚ç‚¹ {node_with_score.node.node_id} å› åŒ¹é…å†å²è®°å½•è€Œè¢«ææƒ {boost}")
            
            # å†ä½¿ç”¨é‡æ’åºæ¨¡å‹
            reranked_nodes = self.reranker.postprocess_nodes(retrieved_nodes, query_bundle=QueryBundle(query_str=query))
            return reranked_nodes[:top_n]
        
        else:
            logger.error(f"Unknown rerank strategy: {strategy}")
            return retrieved_nodes[:top_n]

    def generate(self, query: str, context_nodes: List[NodeWithScore]) -> str:
        """
        æ ¹æ®ä¸Šä¸‹æ–‡èŠ‚ç‚¹ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚
        """
        logger.info("Generating final answer.")
        
        # æ„å»ºå‚è€ƒèµ„æ–™æ–‡æœ¬ï¼Œæ ¼å¼ä¸rag.pyä¿æŒä¸€è‡´
        sources_text = ""
        for i, node in enumerate(context_nodes):
            try:
                # è·å–èŠ‚ç‚¹çš„å…ƒæ•°æ®
                metadata = node.node.metadata if hasattr(node.node, 'metadata') else {}
                title = metadata.get('title', 'æœªçŸ¥æ ‡é¢˜')
                platform = metadata.get('source', 'æœªçŸ¥å¹³å°')
                content = node.get_content()
                
                # ç²¾ç®€å†…å®¹ï¼Œæœ€å¤šä¿ç•™200ä¸ªå­—ç¬¦
                if len(content) > 200:
                    content = content[:200] + "..."
                
                # ä½¿ç”¨ä¸rag.pyç›¸åŒçš„æ ¼å¼
                sources_text += f"[{i+1}] æ ‡é¢˜ï¼š{title}\næ¥æºï¼š{platform}\nå†…å®¹ï¼š{content}\n\n"
            except Exception as e:
                logger.error(f"å¤„ç†context_node[{i}]å¤±è´¥: {str(e)}")
                sources_text += f"[{i+1}] æ— æ³•å¤„ç†çš„æ¥æº\n\n"
        
        # ä½¿ç”¨ä¸rag.pyç›¸åŒçš„æç¤ºè¯æ ¼å¼
        prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{query}\n\nå‚è€ƒèµ„æ–™ï¼š\n{sources_text}"
        
        try:
            # ä½¿ç”¨ä¸rag.pyç›¸åŒçš„è°ƒç”¨æ–¹å¼ï¼Œæ·»åŠ è¶…æ—¶æ§åˆ¶
            import asyncio
            
            async def _generate_with_timeout():
                loop = asyncio.get_event_loop()
                return await loop.run_in_executor(
                    None, 
                    lambda: self.llm.chat_with_new_conversation(
                        query=prompt,
                        stream=False,
                        openid=f"rag_user_{int(time.time())}"
                    )
                )
            
            # è®¾ç½®30ç§’è¶…æ—¶
            try:
                result = asyncio.run(asyncio.wait_for(_generate_with_timeout(), timeout=30.0))
            except asyncio.TimeoutError:
                logger.warning("ç”Ÿæˆç­”æ¡ˆè¶…æ—¶ï¼ˆ>30ç§’ï¼‰ï¼Œè¿”å›åŸºäºä¸Šä¸‹æ–‡çš„æ‘˜è¦")
                if context_nodes:
                    return f"æ ¹æ®æ‰¾åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼š{sources_text[:300]}..."
                return "æŠ±æ­‰ï¼Œå›ç­”ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åå†è¯•ã€‚"
            
            if isinstance(result, dict) and "response" in result:
                answer = result.get("response", "")
                
                # å¤„ç†å¯èƒ½çš„æ ¼å¼åŒ–å‰ç¼€ï¼Œä¸rag.pyä¿æŒä¸€è‡´
                if answer and (answer.startswith("å›ç­”ï¼š") or answer.startswith("å›ç­”:")):
                    answer = answer[3:].strip()
                    
                return answer or "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆæœ‰æ•ˆå›ç­”ã€‚"
            else:
                logger.warning("Cozeè¿”å›çš„ç»“æœæ ¼å¼ä¸æ­£ç¡®")
                return "æŠ±æ­‰ï¼Œå›ç­”æ ¼å¼å‡ºç°é—®é¢˜ã€‚"
        except Exception as e:
            logger.error(f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {e}")
            # å¦‚æœLLMå¤±è´¥ï¼Œè¿”å›åŸºäºä¸Šä¸‹æ–‡çš„ç®€å•æ‘˜è¦
            if context_nodes:
                return f"æ ¹æ®æ‰¾åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼Œ{sources_text[:300]}..."
            return f"æŠ±æ­‰ï¼Œåœ¨ç”Ÿæˆç­”æ¡ˆæ—¶é‡åˆ°äº†é—®é¢˜: {str(e)}"

    async def _get_user_search_history(self, user_id: str, limit: int = 10) -> List[str]:
        """ä»æ•°æ®åº“è·å–ç”¨æˆ·çš„æœ€è¿‘æœç´¢å†å²è®°å½• (åŒæ­¥ç‰ˆæœ¬)ã€‚"""
        if not user_id:
            return []
        try:
            # ä½¿ç”¨æ­£ç¡®çš„è¡¨å wxapp_search_history å’Œå­—æ®µ keyword
            sql = "SELECT DISTINCT keyword FROM wxapp_search_history WHERE openid = %s ORDER BY search_time DESC LIMIT %s"
            from etl.load import db_core
            # å‡è®¾ db_core æœ‰ä¸€ä¸ªåŒæ­¥æ‰§è¡Œå‡½æ•°
            records = await db_core.execute_query(sql, (user_id, limit), fetch=True)
            if records:
                history = [record['keyword'] for record in records]
                logger.info(f"æˆåŠŸè·å–ç”¨æˆ· {user_id} çš„ {len(history)} æ¡æœç´¢å†å²ã€‚")
                return history
            return []
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ· {user_id} çš„æœç´¢å†å²å¤±è´¥: {e}")
            return []

    def run(self, 
           query: str, 
           top_k_retrieve: int = 20, 
           top_k_rerank: int = 5, 
           user_id: Optional[str] = None,
           skip_generation: bool = False,
           retrieval_strategy: Optional[RetrievalStrategy] = None,
           rerank_strategy: Optional[RerankStrategy] = None,
           filters=None) -> dict:
        """
        æ‰§è¡Œå®Œæ•´çš„RAGæµç¨‹ï¼šæ£€ç´¢ -> é‡æ’ -> ç”Ÿæˆã€‚
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            top_k_retrieve: æ£€ç´¢æ•°é‡
            top_k_rerank: é‡æ’åä¿ç•™æ•°é‡
            user_id: ç”¨æˆ·IDï¼Œç”¨äºä¸ªæ€§åŒ–
            skip_generation: æ˜¯å¦è·³è¿‡LLMç”Ÿæˆæ­¥éª¤
            retrieval_strategy: æ£€ç´¢ç­–ç•¥
            rerank_strategy: é‡æ’åºç­–ç•¥
            filters: Qdrantè¿‡æ»¤å™¨
        """
        logger.info(f"--- Running RAG pipeline for query: '{query}' for user: {user_id} ---")
        logger.info(f"Retrieval strategy: {retrieval_strategy or 'default'}, Rerank strategy: {rerank_strategy or 'default'}")

        # 1. è·å–ç”¨æˆ·å†å²ï¼ˆç”¨äºä¸ªæ€§åŒ–ï¼‰
        search_history = []
        if user_id:
            try:
                import asyncio
                search_history = asyncio.run(self._get_user_search_history(user_id))
            except Exception as e:
                logger.warning(f"è·å–ç”¨æˆ·æœç´¢å†å²å¤±è´¥: {e}")
                search_history = []
        
        # 2. æ£€ç´¢
        retrieved_nodes = self.retrieve(
            query=query, 
            top_k=top_k_retrieve, 
            filters=filters,
            strategy=retrieval_strategy
        )
        
        if not retrieved_nodes:
            return {"answer": "æŠ±æ­‰ï¼Œæœªèƒ½æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚", "contexts": [], "retrieved_texts": []}

        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨äº†Elasticsearchæ£€ç´¢
        used_strategy = retrieval_strategy or self.default_retrieval_strategy
        if used_strategy == RetrievalStrategy.AUTO:
            used_strategy = self._determine_retrieval_strategy(query)
        is_elasticsearch = used_strategy == RetrievalStrategy.ELASTICSEARCH_ONLY
        
        # 3. é‡æ’åº
        reranked_nodes = self.rerank(
            query=query,
            retrieved_nodes=retrieved_nodes,
            top_n=top_k_rerank,
            search_history=search_history,
            strategy=rerank_strategy,
            is_elasticsearch=is_elasticsearch
        )
        
        # æå–å¬å›æ–‡æœ¬
        retrieved_texts = []
        for i, node in enumerate(reranked_nodes, 1):
            content = node.get_content()
            score = getattr(node, 'score', 0.0)
            metadata = node.node.metadata if hasattr(node.node, 'metadata') else {}
            retrieved_texts.append({
                "rank": i,
                "content": content,
                "score": score,
                "title": metadata.get('title', ''),
                "url": metadata.get('url', ''),
                "source": metadata.get('source', '')
            })
        
        # å¦‚æœè·³è¿‡ç”Ÿæˆæ­¥éª¤ï¼Œç›´æ¥è¿”å›å¬å›æ–‡æœ¬
        if skip_generation:
            logger.info("--- RAG pipeline finished (generation skipped) ---")
            return {
                "answer": "æ£€ç´¢å®Œæˆï¼Œå·²è·³è¿‡ç­”æ¡ˆç”Ÿæˆã€‚", 
                "contexts": reranked_nodes,
                "retrieved_texts": retrieved_texts,
                "used_retrieval_strategy": used_strategy.value,
                "used_rerank_strategy": (rerank_strategy or self.default_rerank_strategy).value
            }
        
        # 4. ç”Ÿæˆ
        answer = self.generate(query, reranked_nodes)
        
        logger.info(f"--- RAG pipeline finished ---")
        return {
            "answer": answer, 
            "contexts": reranked_nodes,
            "retrieved_texts": retrieved_texts,
            "used_retrieval_strategy": used_strategy.value,
            "used_rerank_strategy": (rerank_strategy or self.default_rerank_strategy).value
        }

    def retrieve_only(self, 
                     query: str, 
                     top_k_retrieve: int = 20, 
                     top_k_rerank: int = 5, 
                     user_id: Optional[str] = None,
                     retrieval_strategy: Optional[RetrievalStrategy] = None,
                     rerank_strategy: Optional[RerankStrategy] = None,
                     filters=None) -> dict:
        """
        åªæ‰§è¡Œæ£€ç´¢å’Œé‡æ’ï¼Œè·³è¿‡LLMç”Ÿæˆæ­¥éª¤ã€‚
        """
        return self.run(
            query=query, 
            top_k_retrieve=top_k_retrieve, 
            top_k_rerank=top_k_rerank, 
            user_id=user_id, 
            skip_generation=True,
            retrieval_strategy=retrieval_strategy,
            rerank_strategy=rerank_strategy,
            filters=filters
        )

    def get_strategy_combinations(self) -> Dict[str, List[str]]:
        """è·å–æ‰€æœ‰å¯ç”¨çš„ç­–ç•¥ç»„åˆ"""
        available_retrieval = []
        for strategy in RetrievalStrategy:
            if strategy == RetrievalStrategy.AUTO:
                available_retrieval.append(strategy.value)
            elif strategy == RetrievalStrategy.VECTOR_ONLY and self.available_retrievers.get("vector"):
                available_retrieval.append(strategy.value)
            elif strategy == RetrievalStrategy.BM25_ONLY and self.available_retrievers.get("bm25"):
                available_retrieval.append(strategy.value)
            elif strategy == RetrievalStrategy.HYBRID and self.available_retrievers.get("hybrid"):
                available_retrieval.append(strategy.value)
            elif strategy == RetrievalStrategy.ELASTICSEARCH_ONLY and self.available_retrievers.get("elasticsearch"):
                available_retrieval.append(strategy.value)
        
        available_rerank = [strategy.value for strategy in RerankStrategy]
        
        return {
            "retrieval_strategies": available_retrieval,
            "rerank_strategies": available_rerank,
            "available_retrievers": self.available_retrievers
        }


if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹ï¼šå±•ç¤ºä¸åŒçš„ç­–ç•¥ç»„åˆ
    rag_pipeline = RagPipeline()
    
    print("=== å¯ç”¨ç­–ç•¥ç»„åˆ ===")
    strategies = rag_pipeline.get_strategy_combinations()
    print("æ£€ç´¢ç­–ç•¥:", strategies["retrieval_strategies"])
    print("é‡æ’åºç­–ç•¥:", strategies["rerank_strategies"])
    print("å¯ç”¨æ£€ç´¢å™¨:", strategies["available_retrievers"])
    print()
    
    # ç¤ºä¾‹1: è‡ªåŠ¨ç­–ç•¥ï¼ˆé»˜è®¤ï¼‰
    print("=== ç¤ºä¾‹1: è‡ªåŠ¨ç­–ç•¥ ===")
    query1 = "å—å¼€å¤§å­¦çš„æ ¡è®­æ˜¯ä»€ä¹ˆï¼Ÿ"
    result1 = rag_pipeline.run(query=query1)
    print(f"æŸ¥è¯¢: {query1}")
    print(f"ä½¿ç”¨çš„æ£€ç´¢ç­–ç•¥: {result1['used_retrieval_strategy']}")
    print(f"ä½¿ç”¨çš„é‡æ’åºç­–ç•¥: {result1['used_rerank_strategy']}")
    print(f"ç­”æ¡ˆ: {result1['answer'][:100]}...")
    print()

    # ç¤ºä¾‹2: æŒ‡å®šç­–ç•¥ç»„åˆ
    print("=== ç¤ºä¾‹2: æŒ‡å®šç­–ç•¥ç»„åˆ ===")
    query2 = "å—å¼€å¤§å­¦*å­¦é™¢"
    result2 = rag_pipeline.run(
        query=query2,
        retrieval_strategy=RetrievalStrategy.ELASTICSEARCH_ONLY,
        rerank_strategy=RerankStrategy.PAGERANK_ONLY
    )
    print(f"æŸ¥è¯¢: {query2}")
    print(f"ä½¿ç”¨çš„æ£€ç´¢ç­–ç•¥: {result2['used_retrieval_strategy']}")
    print(f"ä½¿ç”¨çš„é‡æ’åºç­–ç•¥: {result2['used_rerank_strategy']}")
    print()

    # ç¤ºä¾‹3: ä»…æ£€ç´¢æ¨¡å¼
    print("=== ç¤ºä¾‹3: ä»…æ£€ç´¢æ¨¡å¼ ===")
    query3 = "äººå·¥æ™ºèƒ½"
    result3 = rag_pipeline.retrieve_only(
        query=query3,
        retrieval_strategy=RetrievalStrategy.HYBRID,
        rerank_strategy=RerankStrategy.BGE_RERANKER
    )
    print(f"æŸ¥è¯¢: {query3}")
    print(f"æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡: {len(result3['retrieved_texts'])}")
    print(f"ä½¿ç”¨çš„æ£€ç´¢ç­–ç•¥: {result3['used_retrieval_strategy']}")
    print()

    # ç¤ºä¾‹4: ä¸ªæ€§åŒ–æ£€ç´¢
    print("=== ç¤ºä¾‹4: ä¸ªæ€§åŒ–æ£€ç´¢ ===")
    query4 = "è®¡ç®—æœºä¸“ä¸š"
    result4 = rag_pipeline.run(
        query=query4,
        user_id="test_user_123",
        retrieval_strategy=RetrievalStrategy.VECTOR_ONLY,
        rerank_strategy=RerankStrategy.PERSONALIZED
    )
    print(f"æŸ¥è¯¢: {query4}")
    print(f"ä½¿ç”¨çš„æ£€ç´¢ç­–ç•¥: {result4['used_retrieval_strategy']}")
    print(f"ä½¿ç”¨çš„é‡æ’åºç­–ç•¥: {result4['used_rerank_strategy']}")
    print()
